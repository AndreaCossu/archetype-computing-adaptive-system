{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KY dimension for a single module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from experiments.attractors_general import main\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from itertools import product\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# defining the params to test\n",
    "inps = [0.1, 1.0, 10.0]\n",
    "hids = [2, 10]\n",
    "rhos = [0.5, 0.9, 10.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kyresults = {}\n",
    "for inp_scaling, n_hid, rho in product(inps, hids, rhos):\n",
    "    print(f\"inp_scaling: {inp_scaling}, n_hid: {n_hid}, rho: {rho}\")\n",
    "    directory = f'../results/results_single/rho_{rho}_nhid_{n_hid}_inp_scaling_{inp_scaling}_timesteps_3000'\n",
    "    seq_len = 2000  # timesteps - washout\n",
    "    n_init_states = 1000\n",
    "    n_inp = 1\n",
    "\n",
    "\n",
    "    trajectories = np.load(os.path.join(directory, 'all_states.npy'))  # (n_init_states, timesteps, hidden_size)\n",
    "    filename = \"lyapunov_rnn.dat\"\n",
    "\n",
    "    input_signals = np.load(os.path.join(directory, 'u_timeseries.npy'))\n",
    "\n",
    "    # move files from the saved directory to the current directory\n",
    "    shutil.move(os.path.join(directory, \"W.csv\"), \"W.csv\")\n",
    "    shutil.move(os.path.join(directory, \"V.csv\"), \"V.csv\")\n",
    "    shutil.move(os.path.join(directory, \"b.csv\"), \"b.csv\")\n",
    "\n",
    "    kds = []\n",
    "    for i, traj in enumerate(tqdm(trajectories)):\n",
    "        input_signal = np.expand_dims(input_signals[i], axis=-1) # (seq_len, 1)\n",
    "        np.savetxt(\"u_timeseries.csv\", input_signal, delimiter=\",\", fmt=\"%.6f\")\n",
    "        np.savetxt(\"h_traj.csv\", traj, delimiter=',', fmt=\"%.6f\")\n",
    "\n",
    "        # call rnn_lyap with parameters n_hid, seq_len, n_inp\n",
    "        os.system(f\"./rnn_lyap {n_hid} {seq_len} {n_inp}\")\n",
    "\n",
    "        data = np.loadtxt(filename)\n",
    "        # Extract time (first column) and exponents (remaining columns)\n",
    "        time = data[:, 0]\n",
    "        lyapunov_exponents = data[:, 1:]\n",
    "\n",
    "\n",
    "        # Plot each Lyapunov exponent as a function of time\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # # plot the zero line for reference in black dashed line\n",
    "        # plt.plot(time, np.zeros_like(time), color='black', linestyle='--', linewidth=1)\n",
    "        # for i in range(lyapunov_exponents.shape[1]):\n",
    "        #     plt.plot(time, lyapunov_exponents[:, i], label=f\"LE {i+1}\")\n",
    "\n",
    "        # plt.xlabel(\"Time\")\n",
    "        # plt.ylabel(\"Lyapunov Exponents\")\n",
    "        # plt.title(\"Convergence of Lyapunov Exponents in RNN\")\n",
    "        # plt.legend()\n",
    "        # plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        best_approx_lyaps = lyapunov_exponents[-1, :]\n",
    "        # print(best_approx_lyaps)\n",
    "\n",
    "        # Example: lyapunov_exponents.shape is (N,)\n",
    "        # Make sure the spectrum is sorted in descending order\n",
    "        best_approx_lyaps = np.sort(best_approx_lyaps)[::-1]\n",
    "\n",
    "        if np.any(best_approx_lyaps > 0):\n",
    "            # Cumulative sum\n",
    "            cumsum = np.cumsum(best_approx_lyaps)\n",
    "\n",
    "            # Find j: largest index where cumulative sum is still >= 0\n",
    "            j = np.where(cumsum >= 0)[0][-1]  # last index satisfying sum >= 0\n",
    "\n",
    "            # print(\"j (number of non-negative LEs):\", j + 1)\n",
    "\n",
    "            # Compute Kaplan-Yorke dimension\n",
    "            if j + 1 < len(best_approx_lyaps):\n",
    "                D_KY = j + 1 + cumsum[j] / abs(best_approx_lyaps[j + 1])\n",
    "            else:\n",
    "                # All exponents non-negative \n",
    "                D_KY = len(best_approx_lyaps)\n",
    "        else:\n",
    "            # All exponents are non-positive\n",
    "            D_KY = 0\n",
    "        # print(\"******************\")\n",
    "        #print(\"Kaplan-Yorke dimension:\", D_KY)\n",
    "        # print(\"******************\")\n",
    "        kds.append(D_KY)\n",
    "\n",
    "    print(f\"Kaplan-Yorke dimension over trajectories: {np.mean(kds)} ± {np.std(kds)}\")\n",
    "    max_idx = np.argmax(kds)\n",
    "    min_idx = np.argmin(kds)\n",
    "    print(f\"Max Kaplan-Yorke at index {max_idx} with value {kds[max_idx]}\")\n",
    "    print(f\"Min Kaplan-Yorke at index {min_idx} with value {kds[min_idx]}\")\n",
    "\n",
    "    # move files back to the saved directory\n",
    "    shutil.move(\"W.csv\", os.path.join(directory, \"W.csv\"))\n",
    "    shutil.move(\"V.csv\", os.path.join(directory, \"V.csv\"))\n",
    "    shutil.move(\"b.csv\", os.path.join(directory, \"b.csv\"))\n",
    "\n",
    "    kyresults[(inp_scaling, n_hid, rho)] = kds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_scaling=0.1, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=0.1, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=0.1, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=0.1, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=0.1, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=0.1, n_hid=10, rho=10.0: KD mean=0.43198965536242784 ± std=0.5358651632698999, max=1.1564159450925897, min=0.0\n",
      "inp_scaling=1.0, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=1.0, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=1.0, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=1.0, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=1.0, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=1.0, n_hid=10, rho=10.0: KD mean=0.42510915503891306 ± std=0.5278199391677835, max=1.1558690581719193, min=0.0\n",
      "inp_scaling=10.0, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=10.0, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=10.0, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=10.0, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=10.0, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "inp_scaling=10.0, n_hid=10, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n"
     ]
    }
   ],
   "source": [
    "for k, v in kyresults.items():\n",
    "    inp_scaling, n_hid, rho = k\n",
    "    print(f\"inp_scaling={inp_scaling}, n_hid={n_hid}, rho={rho}: KD mean={np.mean(v)} ± std={np.std(v)}, max={np.max(v)}, min={np.min(v)}\")\n",
    "\n",
    "    # plot histogram\n",
    "    dir = f'/scratch/a.cossu/results_single/rho_{rho}_nhid_{n_hid}_inp_scaling_{inp_scaling}_timesteps_3000'\n",
    "    plt.figure()\n",
    "    plt.hist(kyresults[(inp_scaling, n_hid, rho)], bins=30)\n",
    "    plt.savefig(os.path.join(dir, \"ky_histogram.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KY dimension for a collective of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import shutil\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inps = [0.1, 1.0, 10.0]\n",
    "hids = [2, 10, 100, 1000]\n",
    "rhos = [0.5, 0.9, 10.0]\n",
    "\n",
    "n_modules = 2\n",
    "\n",
    "kyresults = [{} for _ in range(n_modules)]\n",
    "\n",
    "for inp_scaling, n_hid, rho in product(inps, hids, rhos):\n",
    "    print(f\"inp_scaling: {inp_scaling}, n_hid: {n_hid}, rho: {rho}\")\n",
    "    directory = f'../results/results_collective/mod1_rho_{rho}_nhid_{n_hid}_timesteps_1000_inpscaling_{inps}'\n",
    "    seq_len = 2000  # timesteps - washout\n",
    "    n_init_states = 1000\n",
    "    n_inp = n_hid\n",
    "\n",
    "    input_signal = torch.load(os.path.join(directory, f\"input_signals.pt\"))\n",
    "\n",
    "    for i in range(n_modules):\n",
    "        print(f\"Processing module {i}\")\n",
    "        trajectories = np.load(os.path.join(directory, f'all_states{i}.npy')) \n",
    "\n",
    "        filename = \"lyapunov_rnn.dat\"\n",
    "\n",
    "        # move files from the saved directory to the current directory\n",
    "        shutil.move(os.path.join(directory, f\"W_{i}.csv\"), f\"W.csv\")\n",
    "        shutil.move(os.path.join(directory, f\"V_{i}.csv\"), f\"V.csv\")\n",
    "        shutil.move(os.path.join(directory, f\"b_{i}.csv\"), f\"b.csv\")\n",
    "\n",
    "        kds = []\n",
    "        for t, traj in enumerate(tqdm(trajectories)):\n",
    "            np.savetxt(os.path.join(\"u_timeseries.csv\"), input_signal[i][t].cpu().numpy(), delimiter=\",\", fmt=\"%.6f\")\n",
    "            np.savetxt(\"h_traj.csv\", traj, delimiter=',', fmt=\"%.6f\")\n",
    "\n",
    "            # call rnn_lyap with parameters n_hid, seq_len, n_inp\n",
    "            os.system(f\"./rnn_lyap {n_hid} {seq_len} {n_inp}\")\n",
    "\n",
    "            data = np.loadtxt(filename)\n",
    "            # Extract time (first column) and exponents (remaining columns)\n",
    "            time = data[:, 0]\n",
    "            lyapunov_exponents = data[:, 1:]\n",
    "\n",
    "\n",
    "            # Plot each Lyapunov exponent as a function of time\n",
    "            # plt.figure(figsize=(10, 6))\n",
    "            # # plot the zero line for reference in black dashed line\n",
    "            # plt.plot(time, np.zeros_like(time), color='black', linestyle='--', linewidth=1)\n",
    "            # for i in range(lyapunov_exponents.shape[1]):\n",
    "            #     plt.plot(time, lyapunov_exponents[:, i], label=f\"LE {i+1}\")\n",
    "\n",
    "            # plt.xlabel(\"Time\")\n",
    "            # plt.ylabel(\"Lyapunov Exponents\")\n",
    "            # plt.title(\"Convergence of Lyapunov Exponents in RNN\")\n",
    "            # plt.legend()\n",
    "            # plt.grid(True, linestyle='--', alpha=0.6)\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "\n",
    "            best_approx_lyaps = lyapunov_exponents[-1, :]\n",
    "            # print(best_approx_lyaps)\n",
    "\n",
    "            # Example: lyapunov_exponents.shape is (N,)\n",
    "            # Make sure the spectrum is sorted in descending order\n",
    "            best_approx_lyaps = np.sort(best_approx_lyaps)[::-1]\n",
    "\n",
    "            if np.any(best_approx_lyaps > 0):\n",
    "                # Cumulative sum\n",
    "                cumsum = np.cumsum(best_approx_lyaps)\n",
    "\n",
    "                # Find j: largest index where cumulative sum is still >= 0\n",
    "                j = np.where(cumsum >= 0)[0][-1]  # last index satisfying sum >= 0\n",
    "\n",
    "                # print(\"j (number of non-negative LEs):\", j + 1)\n",
    "\n",
    "                # Compute Kaplan-Yorke dimension\n",
    "                if j + 1 < len(best_approx_lyaps):\n",
    "                    D_KY = j + 1 + cumsum[j] / abs(best_approx_lyaps[j + 1])\n",
    "                else:\n",
    "                    # All exponents non-negative \n",
    "                    D_KY = len(best_approx_lyaps)\n",
    "            else:\n",
    "                # All exponents are non-positive\n",
    "                D_KY = 0\n",
    "            # print(\"******************\")\n",
    "            #print(\"Kaplan-Yorke dimension:\", D_KY)\n",
    "            # print(\"******************\")\n",
    "            kds.append(D_KY)\n",
    "\n",
    "        print(f\"Kaplan-Yorke dimension over trajectories: {np.mean(kds)} ± {np.std(kds)}\")\n",
    "        max_idx = np.argmax(kds)\n",
    "        min_idx = np.argmin(kds)\n",
    "        print(f\"Max Kaplan-Yorke at index {max_idx} with value {kds[max_idx]}\")\n",
    "        print(f\"Min Kaplan-Yorke at index {min_idx} with value {kds[min_idx]}\")\n",
    "        \n",
    "        # move files back to the saved directory\n",
    "        shutil.move(\"W.csv\", os.path.join(directory, f\"W_{i}.csv\"))\n",
    "        shutil.move(\"V.csv\", os.path.join(directory, f\"V_{i}.csv\"))\n",
    "        shutil.move(\"b.csv\", os.path.join(directory, f\"b_{i}.csv\"))\n",
    "        kyresults[i][(inp_scaling, n_hid, rho)] = kds\n",
    "        print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module 0 inp_scaling=0.1, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=0.1, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=0.1, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=0.1, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=0.1, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=0.1, n_hid=10, rho=10.0: KD mean=0.24836980438745454 ± std=0.4395684170151863, max=1.0310220534371826, min=0.0\n",
      "Module 0 inp_scaling=1.0, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=1.0, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=1.0, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=1.0, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=1.0, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=1.0, n_hid=10, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=10.0, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=10.0, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=10.0, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=10.0, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=10.0, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 0 inp_scaling=10.0, n_hid=10, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=0.1, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=0.1, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=0.1, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=0.1, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=0.1, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=0.1, n_hid=10, rho=10.0: KD mean=1.4424532816017888 ± std=0.07710421894280652, max=1.5047914595680707, min=0.0\n",
      "Module 1 inp_scaling=1.0, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=1.0, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=1.0, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=1.0, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=1.0, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=1.0, n_hid=10, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=10.0, n_hid=2, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=10.0, n_hid=2, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=10.0, n_hid=2, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=10.0, n_hid=10, rho=0.5: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=10.0, n_hid=10, rho=0.9: KD mean=0.0 ± std=0.0, max=0, min=0\n",
      "Module 1 inp_scaling=10.0, n_hid=10, rho=10.0: KD mean=0.0 ± std=0.0, max=0, min=0\n"
     ]
    }
   ],
   "source": [
    "for m, kyd in enumerate(kyresults):  # for each module\n",
    "    for k, v in kyd.items():\n",
    "        inp_scaling, n_hid, rho = k\n",
    "        print(f\"Module {m} inp_scaling={inp_scaling}, n_hid={n_hid}, rho={rho}: KD mean={np.mean(v)} ± std={np.std(v)}, max={np.max(v)}, min={np.min(v)}\")\n",
    "\n",
    "        # plot histogram\n",
    "        dir = f'/scratch/a.cossu/results_collective/mod2_rho_{rho}_nhid_{n_hid}_timesteps_3000_inpscaling_{inp_scaling}'\n",
    "        plt.figure()\n",
    "        plt.hist(kyd[(inp_scaling, n_hid, rho)], bins=30)\n",
    "        plt.savefig(os.path.join(dir, f\"ky_histogram_mod{m}.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a single trajectory at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m plot_only = \u001b[32m5\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# load from pca\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m trajectories = \u001b[43mnp\u001b[49m.load(os.path.join(directory, filename))  \u001b[38;5;66;03m# (n_init_states*timesteps, 2)\u001b[39;00m\n\u001b[32m     18\u001b[39m idx = \u001b[32m0\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, trajectories.shape[\u001b[32m0\u001b[39m], seq_len):\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# plot a single trajectory\n",
    "def plot_trajectory(pca_traj, idx):\n",
    "    plt.figure()\n",
    "    plt.scatter(pca_traj[0], pca_traj[1], s=1)\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.savefig(f\"trajectory{idx}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "directory = '/scratch/a.cossu/results_collective/mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_0.1'\n",
    "filename = 'pca_result_1.npy'\n",
    "seq_len = 2000  # timesteps - washout\n",
    "plot_how_many = 200  # plot the first plot_how_many trajectories\n",
    "plot_only = 185 # set to -1 to plot plot_how_many trajectories, or set to a specific index to plot only that trajectory\n",
    "\n",
    "if plot_only >= 0:\n",
    "    plot_how_many = plot_only + 1\n",
    "\n",
    "# load from pca\n",
    "trajectories = np.load(os.path.join(directory, filename))  # (n_init_states*timesteps, 2)\n",
    "idx = 0\n",
    "for k in range(0, trajectories.shape[0], seq_len):\n",
    "    traj = trajectories[k:k+seq_len]\n",
    "\n",
    "    if plot_only < 0 or idx == plot_only:\n",
    "        plot_trajectory(traj, idx=idx)\n",
    "        if plot_only >= 0:\n",
    "            break\n",
    "    idx += 1\n",
    "\n",
    "    if idx >= plot_how_many:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all trajectory.png \n",
    "import os\n",
    "for file in os.listdir():\n",
    "    if file.startswith(\"trajectory\") and file.endswith(\".png\"):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKDIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: rho_0.5_nhid_2_inp_scaling_0.1_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.5_nhid_2_inp_scaling_1.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.5_nhid_2_inp_scaling_10.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_0.1_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_1.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_10.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_0.1_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_1.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_10.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_0.1_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_1.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_10.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_0.1_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_1.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_10.0_timesteps_3000, Correlation Dimension: nan\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_0.1_timesteps_3000, Correlation Dimension: 1.4738525037173253\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_1.0_timesteps_3000, Correlation Dimension: 1.4738525037173253\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_10.0_timesteps_3000, Correlation Dimension: 1.4738525037173253\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_0.1, Correlation Dimension: [112.54282465299814, 112.44078746954183]\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_1.0, Correlation Dimension: [98.88093457019299, 99.54457099398847]\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_10.0, Correlation Dimension: [116.85919158779207, 111.93650677150056]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_0.1, Correlation Dimension: [176.21012280736767, 189.8131837184257]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_1.0, Correlation Dimension: [19.675508224556957, 19.689629044378773]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_10.0, Correlation Dimension: [10.470567787718462, 10.519728683075783]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_0.1, Correlation Dimension: [83.0749185331063, 64.3901523309245]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_1.0, Correlation Dimension: [56.65881485758969, 56.89177693454769]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_10.0, Correlation Dimension: [110.25429460777737, 109.65859170099601]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_0.1, Correlation Dimension: [180.4174943942527, 190.7869798463247]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_1.0, Correlation Dimension: [30.113802071681402, 30.765473417114197]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_10.0, Correlation Dimension: [10.899077483204389, 10.919819048669195]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_0.1, Correlation Dimension: [59.20366125846282, 54.330716510877494]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_1.0, Correlation Dimension: [21.520308618803913, 7.762608939681045]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_10.0, Correlation Dimension: [16.242634567099365, 17.335926143444553]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_0.1, Correlation Dimension: [4.244954689323452, 4.397520360946519]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_1.0, Correlation Dimension: [109.61638487750439, 291.07041498404993]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_10.0, Correlation Dimension: [30.31632049490206, 30.390188229526235]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skdim\n",
    "\n",
    "\n",
    "foldernames = [\"results_single\", \"results_collective\"]\n",
    "for foldername in foldernames:\n",
    "    for folder in os.listdir(f\"/scratch/a.cossu/{foldername}/\"):\n",
    "        folder_path = os.path.join(f\"/scratch/a.cossu/{foldername}/\", folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            if foldername == \"results_collective\":\n",
    "                n_mods = int(folder.split(\"_\")[0].replace(\"mod\", \"\"))\n",
    "                corrdims = []\n",
    "                for i in range(n_mods):\n",
    "                    all_states = np.load(os.path.join(folder_path, f\"all_states{i}.npy\"))\n",
    "                    reshaped_states = all_states.reshape((all_states.shape[0], -1))\n",
    "                    corr_dim = skdim.id.CorrInt().fit_transform(reshaped_states)\n",
    "                    corrdims.append(corr_dim)\n",
    "                print(f\"Folder: {folder}, Correlation Dimension: {[float(c) for c in corrdims]}\")\n",
    "                # write corrdims to a file in folder\n",
    "                with open(os.path.join(folder_path, \"correlation_dimensions.txt\"), \"w\") as f:\n",
    "                    for i, cd in enumerate(corrdims):\n",
    "                        f.write(f\"{i}: {cd}\\n\")\n",
    "            else:\n",
    "                all_states = np.load(os.path.join(folder_path, \"all_states.npy\"))\n",
    "                reshaped_states = all_states.reshape((all_states.shape[0], -1))\n",
    "                corr_dim = skdim.id.CorrInt().fit_transform(reshaped_states)\n",
    "                print(f\"Folder: {folder}, Correlation Dimension: {corr_dim}\")\n",
    "                with open(os.path.join(folder_path, \"correlation_dimensions.txt\"), \"w\") as f:\n",
    "                    f.write(f\"{corr_dim}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping {folder_path}, not a directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold-Adaptive Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: rho_0.5_nhid_2_inp_scaling_0.1_timesteps_3000, Manifold Dimension: nan\n",
      "Folder: rho_0.5_nhid_2_inp_scaling_1.0_timesteps_3000, Manifold Dimension: nan\n",
      "Folder: rho_0.5_nhid_2_inp_scaling_10.0_timesteps_3000, Manifold Dimension: nan\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_0.1_timesteps_3000, Manifold Dimension: nan\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_1.0_timesteps_3000, Manifold Dimension: nan\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_10.0_timesteps_3000, Manifold Dimension: nan\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_0.1_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_1.0_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_10.0_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_0.1_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_1.0_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_10.0_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_0.1_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_1.0_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_10.0_timesteps_3000, Manifold Dimension: inf\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_0.1_timesteps_3000, Manifold Dimension: 633241.8640053609\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_1.0_timesteps_3000, Manifold Dimension: 633241.8640053609\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_10.0_timesteps_3000, Manifold Dimension: 633241.8640053609\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_0.1, Manifold Dimension: [151.73790548493662, 148.21253686713248]\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_1.0, Manifold Dimension: [105.82236847436364, 107.87305919253285]\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_10.0, Manifold Dimension: [125.90325416261376, 124.07201373316967]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_0.1, Manifold Dimension: [233.1844335397014, 259.78213478659677]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_1.0, Manifold Dimension: [23.13720150425776, 23.289958686500484]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_10.0, Manifold Dimension: [13.321517100870366, 13.289782787694698]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_0.1, Manifold Dimension: [103.25400814562776, 77.40610265073164]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_1.0, Manifold Dimension: [61.73542540531102, 63.19305428096023]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_10.0, Manifold Dimension: [116.57652184103772, 116.05132601520316]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_0.1, Manifold Dimension: [235.9364649069499, 239.19304943283302]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_1.0, Manifold Dimension: [32.94314652711001, 33.484384270578445]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_10.0, Manifold Dimension: [13.778008389072777, 13.775642968558078]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_0.1, Manifold Dimension: [154.54445879628173, 152.7662842316426]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_1.0, Manifold Dimension: [438.2580312239806, 938.5546981699828]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_10.0, Manifold Dimension: [19.257732040437645, 20.99556622206381]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_0.1, Manifold Dimension: [36.9063769200164, 202.3317798566067]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_1.0, Manifold Dimension: [120.57772931886142, 313.16315047947916]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_10.0, Manifold Dimension: [33.835912793823155, 34.25893490294539]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skdim\n",
    "\n",
    "\n",
    "foldernames = [\"results_single\", \"results_collective\"]\n",
    "for foldername in foldernames:\n",
    "    for folder in os.listdir(f\"/scratch/a.cossu/{foldername}/\"):\n",
    "        folder_path = os.path.join(f\"/scratch/a.cossu/{foldername}/\", folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            if foldername == \"results_collective\":\n",
    "                n_mods = int(folder.split(\"_\")[0].replace(\"mod\", \"\"))\n",
    "                corrdims = []\n",
    "                for i in range(n_mods):\n",
    "                    all_states = np.load(os.path.join(folder_path, f\"all_states{i}.npy\"))\n",
    "                    reshaped_states = all_states.reshape((all_states.shape[0], -1))\n",
    "                    corr_dim = skdim.id.MADA().fit_transform(reshaped_states)\n",
    "                    corrdims.append(corr_dim)\n",
    "                print(f\"Folder: {folder}, Manifold Dimension: {[float(c) for c in corrdims]}\")\n",
    "                with open(os.path.join(folder_path, \"manifold_dimensions.txt\"), \"w\") as f:\n",
    "                    for i, cd in enumerate(corrdims):\n",
    "                        f.write(f\"{i}: {cd}\\n\")\n",
    "            else:\n",
    "                all_states = np.load(os.path.join(folder_path, \"all_states.npy\"))\n",
    "                reshaped_states = all_states.reshape((all_states.shape[0], -1))\n",
    "                corr_dim = skdim.id.MADA().fit_transform(reshaped_states)\n",
    "                print(f\"Folder: {folder}, Manifold Dimension: {corr_dim}\")\n",
    "                with open(os.path.join(folder_path, \"manifold_dimensions.txt\"), \"w\") as f:\n",
    "                    f.write(f\"{corr_dim}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping {folder_path}, not a directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lPCA dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: rho_0.5_nhid_2_inp_scaling_0.1_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.5_nhid_2_inp_scaling_1.0_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.5_nhid_2_inp_scaling_10.0_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_0.1_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_1.0_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.5_nhid_10_inp_scaling_10.0_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_0.1_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_1.0_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.9_nhid_2_inp_scaling_10.0_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_0.1_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_1.0_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_0.9_nhid_10_inp_scaling_10.0_timesteps_3000, lPCA Dimension: 0\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_0.1_timesteps_3000, lPCA Dimension: 1\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_1.0_timesteps_3000, lPCA Dimension: 1\n",
      "Folder: rho_10.0_nhid_2_inp_scaling_10.0_timesteps_3000, lPCA Dimension: 1\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_0.1_timesteps_3000, lPCA Dimension: 4\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_1.0_timesteps_3000, lPCA Dimension: 4\n",
      "Folder: rho_10.0_nhid_10_inp_scaling_10.0_timesteps_3000, lPCA Dimension: 4\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_0.1, lPCA Dimension: [809.0, 813.0]\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_1.0, lPCA Dimension: [483.0, 506.0]\n",
      "Folder: mod2_rho_0.5_nhid_2_timesteps_3000_inpscaling_10.0, lPCA Dimension: [594.0, 581.0]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_0.1, lPCA Dimension: [999.0, 999.0]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_1.0, lPCA Dimension: [45.0, 45.0]\n",
      "Folder: mod2_rho_0.5_nhid_10_timesteps_3000_inpscaling_10.0, lPCA Dimension: [21.0, 21.0]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_0.1, lPCA Dimension: [484.0, 302.0]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_1.0, lPCA Dimension: [201.0, 203.0]\n",
      "Folder: mod2_rho_0.9_nhid_2_timesteps_3000_inpscaling_10.0, lPCA Dimension: [544.0, 537.0]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_0.1, lPCA Dimension: [999.0, 999.0]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_1.0, lPCA Dimension: [78.0, 78.0]\n",
      "Folder: mod2_rho_0.9_nhid_10_timesteps_3000_inpscaling_10.0, lPCA Dimension: [23.0, 23.0]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_0.1, lPCA Dimension: [1.0, 1.0]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_1.0, lPCA Dimension: [1.0, 1.0]\n",
      "Folder: mod2_rho_10.0_nhid_2_timesteps_3000_inpscaling_10.0, lPCA Dimension: [36.0, 37.0]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_0.1, lPCA Dimension: [3.0, 1.0]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_1.0, lPCA Dimension: [511.0, 999.0]\n",
      "Folder: mod2_rho_10.0_nhid_10_timesteps_3000_inpscaling_10.0, lPCA Dimension: [75.0, 75.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skdim\n",
    "\n",
    "\n",
    "foldernames = [\"results_single\", \"results_collective\"]\n",
    "for foldername in foldernames:\n",
    "    for folder in os.listdir(f\"/scratch/a.cossu/{foldername}/\"):\n",
    "        folder_path = os.path.join(f\"/scratch/a.cossu/{foldername}/\", folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            if foldername == \"results_collective\":\n",
    "                n_mods = int(folder.split(\"_\")[0].replace(\"mod\", \"\"))\n",
    "                corrdims = []\n",
    "                for i in range(n_mods):\n",
    "                    all_states = np.load(os.path.join(folder_path, f\"all_states{i}.npy\"))\n",
    "                    reshaped_states = all_states.reshape((all_states.shape[0], -1))\n",
    "                    corr_dim = skdim.id.lPCA().fit_transform(reshaped_states)\n",
    "                    corrdims.append(corr_dim)\n",
    "                print(f\"Folder: {folder}, lPCA Dimension: {[float(c) for c in corrdims]}\")\n",
    "                # write corrdims to a file in folder\n",
    "                with open(os.path.join(folder_path, \"lpca_dimensions.txt\"), \"w\") as f:\n",
    "                    for i, cd in enumerate(corrdims):\n",
    "                        f.write(f\"{i}: {cd}\\n\")\n",
    "            else:\n",
    "                all_states = np.load(os.path.join(folder_path, \"all_states.npy\"))\n",
    "                reshaped_states = all_states.reshape((all_states.shape[0], -1))\n",
    "                corr_dim = skdim.id.lPCA().fit_transform(reshaped_states)\n",
    "                print(f\"Folder: {folder}, lPCA Dimension: {corr_dim}\")\n",
    "                with open(os.path.join(folder_path, \"lpca_dimensions.txt\"), \"w\") as f:\n",
    "                    f.write(f\"{corr_dim}\\n\")\n",
    "        else:\n",
    "            print(f\"Skipping {folder_path}, not a directory.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
